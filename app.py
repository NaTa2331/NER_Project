import streamlit as st
import spacy

# Load spaCy model
spacy_model_path = "IE Model"
nlp_spacy = spacy.load(spacy_model_path)

# Initialize session state for storing user inputs
if "total_inputs" not in st.session_state:
    st.session_state.total_inputs = []

# Dictionary chuyá»ƒn Ä‘á»•i mÃ£ thá»±c thá»ƒ sang tÃªn Ä‘áº§y Ä‘á»§ vÃ  mÃ´ táº£
ENTITY_DESCRIPTIONS = {
    "B-ORG": "TÃªn tá»• chá»©c (Báº¯t Ä‘áº§u thá»±c thá»ƒ)",
    "I-ORG": "TÃªn tá»• chá»©c (Tiáº¿p tá»¥c thá»±c thá»ƒ)",
    "B-LOC": "Äá»‹a Ä‘iá»ƒm (Báº¯t Ä‘áº§u thá»±c thá»ƒ)",
    "I-LOC": "Äá»‹a Ä‘iá»ƒm (Tiáº¿p tá»¥c thá»±c thá»ƒ)",
    "B-PER": "TÃªn ngÆ°á»i (Báº¯t Ä‘áº§u thá»±c thá»ƒ)",
    "I-PER": "TÃªn ngÆ°á»i (Tiáº¿p tá»¥c thá»±c thá»ƒ)",
    "B-MISC": "Thá»±c thá»ƒ khÃ¡c (Báº¯t Ä‘áº§u thá»±c thá»ƒ)n",
    "I-MISC": "Thá»±c thá»ƒ khÃ¡c (Tiáº¿p tá»¥c thá»±c thá»ƒ)",
    "O": "KhÃ´ng thuá»™c thá»±c thá»ƒ nÃ o",
}

def extract_information_spacy(sentence):
    doc = nlp_spacy(sentence)
    extracted_info = {}
    for ent in doc.ents:
        extracted_info.setdefault(ent.label_, []).append(ent.text)
    return extracted_info

def format_output(text, entities):
    output = f"### VÄƒn báº£n gá»‘c:\n{text}\n\n"
    output += "### Káº¿t quáº£ nháº­n diá»‡n thá»±c thá»ƒ:\n"
    
    total_entities = sum(len(tokens) for tokens in entities.values())
    output += f"**Tá»•ng sá»‘ thá»±c thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c: {total_entities}**\n\n"

    if entities:
        output += "| Loáº¡i thá»±c thá»ƒ | GiÃ¡ trá»‹ |\n"
        output += "|---------------|---------|\n"
        for entity_type, tokens in entities.items():
            unique_tokens = list(set(tokens))  # Loáº¡i bá» trÃ¹ng láº·p
            description = ENTITY_DESCRIPTIONS.get(entity_type, "Thá»±c thá»ƒ khÃ¡c")
            output += f"| **{description}** | {', '.join(unique_tokens)} |\n"
    else:
        output += "*KhÃ´ng tÃ¬m tháº¥y thá»±c thá»ƒ nÃ o trong vÄƒn báº£n.*"
    
    return output

# Streamlit UI
st.title("ğŸ” á»¨ng dá»¥ng Nháº­n diá»‡n Thá»±c thá»ƒ (NER)")
st.write("á»¨ng dá»¥ng giÃºp trÃ­ch xuáº¥t thÃ´ng tin quan trá»ng tá»« vÄƒn báº£n báº±ng mÃ´ hÃ¬nh AI.")

user_input = st.text_area("Nháº­p vÄƒn báº£n cáº§n phÃ¢n tÃ­ch:", "")

if st.button("Nháº­n diá»‡n thá»±c thá»ƒ"):
    if user_input:
        st.session_state.total_inputs.append(user_input)
        
        # Xá»­ lÃ½ mÃ´ hÃ¬nh spaCy
        extracted_entities_spacy = extract_information_spacy(user_input)
        formatted_text_spacy = format_output(user_input, extracted_entities_spacy)

        # Hiá»ƒn thá»‹ káº¿t quáº£
        st.subheader("ğŸ“Œ Káº¿t quáº£ tá»« mÃ´ hÃ¬nh AI:")
        st.markdown(formatted_text_spacy)
        
        # LÆ°u cáº£ vÄƒn báº£n nháº­p vÃ  káº¿t quáº£ nháº­n dáº¡ng vÃ o tá»‡p
        all_inputs_with_entities = []
        for text in st.session_state.total_inputs:
            extracted_entities_spacy = extract_information_spacy(text)
            formatted_text_spacy = format_output(text, extracted_entities_spacy)
            all_inputs_with_entities.append(formatted_text_spacy)
        
        # Táº¡o tá»‡p Ä‘á»ƒ táº£i xuá»‘ng
        all_inputs_with_entities_text = "\n\n".join(all_inputs_with_entities)
        
        st.download_button(
            label="ğŸ“¥ Táº£i xuá»‘ng káº¿t quáº£ nháº­n diá»‡n",
            data=all_inputs_with_entities_text,
            file_name="ket_qua_ner.txt",
            mime="text/plain"
        )
    else:
        st.warning("âš ï¸ Vui lÃ²ng nháº­p vÄƒn báº£n trÆ°á»›c khi phÃ¢n tÃ­ch.")
