import streamlit as st
import spacy

# Load spaCy model
spacy_model_path = "IE Model"
nlp_spacy = spacy.load(spacy_model_path)

# Initialize session state for storing user inputs
if "total_inputs" not in st.session_state:
    st.session_state.total_inputs = []

# Dictionary chuy·ªÉn ƒë·ªïi m√£ th·ª±c th·ªÉ sang t√™n ƒë·∫ßy ƒë·ªß v√† m√¥ t·∫£
ENTITY_DESCRIPTIONS = {
    "B-ORG": "T√™n t·ªï ch·ª©c (B·∫Øt ƒë·∫ßu th·ª±c th·ªÉ)",
    "I-ORG": "T√™n t·ªï ch·ª©c (Ti·∫øp t·ª•c th·ª±c th·ªÉ)",
    "B-LOC": "ƒê·ªãa ƒëi·ªÉm (B·∫Øt ƒë·∫ßu th·ª±c th·ªÉ)",
    "I-LOC": "ƒê·ªãa ƒëi·ªÉm (Ti·∫øp t·ª•c th·ª±c th·ªÉ)",
    "B-PER": "T√™n ng∆∞·ªùi (B·∫Øt ƒë·∫ßu th·ª±c th·ªÉ)",
    "I-PER": "T√™n ng∆∞·ªùi (Ti·∫øp t·ª•c th·ª±c th·ªÉ)",
    "B-MISC": "Th·ª±c th·ªÉ kh√°c (B·∫Øt ƒë·∫ßu th·ª±c th·ªÉ)n",
    "I-MISC": "Th·ª±c th·ªÉ kh√°c (Ti·∫øp t·ª•c th·ª±c th·ªÉ)",
    "O": "Kh√¥ng thu·ªôc th·ª±c th·ªÉ n√†o",
}

def extract_information_spacy(sentence):
    doc = nlp_spacy(sentence)
    extracted_info = {}
    current_entity = None

    for ent in doc.ents:
        if ent.label_.startswith("B-"):
            if current_entity:
                extracted_info.setdefault(current_entity[0], []).append(" ".join(current_entity[1]))
            current_entity = [ent.label_, [ent.text]]  # Start a new entity
        elif ent.label_.startswith("I-") and current_entity and current_entity[0] == ent.label_[2:]:
            current_entity[1].append(ent.text)  # Continue the entity
        else:
            if current_entity:
                extracted_info.setdefault(current_entity[0], []).append(" ".join(current_entity[1]))
                current_entity = None

    if current_entity:
        extracted_info.setdefault(current_entity[0], []).append(" ".join(current_entity[1]))

    for ent in doc.ents:
        if not ent.label_.startswith("B-") and not ent.label_.startswith("I-"):
            extracted_info.setdefault(ent.label_, []).append(ent.text)

    return extracted_info

def format_output(text, entities):
    output = f"### VƒÉn b·∫£n g·ªëc:\n{text}\n\n"
    output += "### K·∫øt qu·∫£ nh·∫≠n di·ªán th·ª±c th·ªÉ:\n"
    
    total_entities = sum(len(tokens) for tokens in entities.values())
    output += f"**T·ªïng s·ªë th·ª±c th·ªÉ nh·∫≠n di·ªán ƒë∆∞·ª£c: {total_entities}**\n\n"

    if entities:
        output += "| Lo·∫°i th·ª±c th·ªÉ | Gi√° tr·ªã |\n"
        output += "|---------------|---------|\n"
        for entity_type, tokens in entities.items():
            unique_tokens = list(set(tokens))  # Lo·∫°i b·ªè tr√πng l·∫∑p
            description = ENTITY_DESCRIPTIONS.get(entity_type, "Th·ª±c th·ªÉ kh√°c")
            output += f"| **{description}** | {', '.join(unique_tokens)} |\n"
        
        # Add a section for complete phrases for all entity types
        output += "\n### C√°c c·ª•m t·ª´ ho√†n ch·ªânh:\n"
        for entity_type in entities.keys():
            if entity_type.startswith("B-"):
                complete_phrases = entities[entity_type] + entities.get("I-" + entity_type[2:], [])
                output += f"- **C·ª•m t·ª´ {ENTITY_DESCRIPTIONS.get(entity_type, 'kh√°c')}**: {', '.join(set(complete_phrases))}\n"
    else:
        output += "*Kh√¥ng t√¨m th·∫•y th·ª±c th·ªÉ n√†o trong vƒÉn b·∫£n.*"
    
    return output

# Streamlit UI
st.title("üîé ·ª®ng d·ª•ng Nh·∫≠n di·ªán Th·ª±c th·ªÉ (NER)")
st.write("·ª®ng d·ª•ng gi√∫p tr√≠ch xu·∫•t th√¥ng tin quan tr·ªçng t·ª´ vƒÉn b·∫£n b·∫±ng m√¥ h√¨nh AI.")

user_input = st.text_area("Nh·∫≠p vƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch:", "")

if st.button("Nh·∫≠n di·ªán th·ª±c th·ªÉ"):
    if user_input:
        st.session_state.total_inputs.append(user_input)
        
        # X·ª≠ l√Ω m√¥ h√¨nh spaCy
        extracted_entities_spacy = extract_information_spacy(user_input)
        formatted_text_spacy = format_output(user_input, extracted_entities_spacy)

        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        st.subheader("üìå K·∫øt qu·∫£ t·ª´ m√¥ h√¨nh AI:")
        st.markdown(formatted_text_spacy)
        
        # L∆∞u c·∫£ vƒÉn b·∫£n nh·∫≠p v√† k·∫øt qu·∫£ nh·∫≠n d·∫°ng v√†o t·ªáp
        all_inputs_with_entities = []
        for text in st.session_state.total_inputs:
            extracted_entities_spacy = extract_information_spacy(text)
            formatted_text_spacy = format_output(text, extracted_entities_spacy)
            all_inputs_with_entities.append(formatted_text_spacy)
        
        # T·∫°o t·ªáp ƒë·ªÉ t·∫£i xu·ªëng
        all_inputs_with_entities_text = "\n\n".join(all_inputs_with_entities)
        
        st.download_button(
            label="üì• T·∫£i xu·ªëng k·∫øt qu·∫£ nh·∫≠n di·ªán",
            data=all_inputs_with_entities_text,
            file_name="ket_qua_ner.txt",
            mime="text/plain"
        )
    else:
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p vƒÉn b·∫£n tr∆∞·ªõc khi ph√¢n t√≠ch.")
