import streamlit as st
import spacy

# Load spaCy model
spacy_model_path = "IE Model"
nlp_spacy = spacy.load(spacy_model_path)

# Initialize session state for storing user inputs
if "total_inputs" not in st.session_state:
    st.session_state.total_inputs = []

# Dictionary chuy·ªÉn ƒë·ªïi m√£ th·ª±c th·ªÉ sang t√™n ƒë·∫ßy ƒë·ªß
ENTITY_DESCRIPTIONS = {
    "ORG": "T√™n t·ªï ch·ª©c",
    "LOC": "ƒê·ªãa ƒëi·ªÉm",
    "PER": "T√™n ng∆∞·ªùi",
    "MISC": "Th·ª±c th·ªÉ kh√°c"
}

def extract_entities(sentence):
    doc = nlp_spacy(sentence)
    extracted_info = {}
    entity_chunks = []
    
    current_entity = ""
    current_label = ""
    
    for ent in doc.ents:
        if ent.label_ not in ENTITY_DESCRIPTIONS:
            continue
        
        if ent.label_ == current_label:
            current_entity += " " + ent.text  # N·ªëi t·ª´ c√πng lo·∫°i v√†o m·ªôt c·ª•m
        else:
            if current_entity:
                entity_chunks.append((current_label, current_entity))
            current_entity = ent.text
            current_label = ent.label_
    
    if current_entity:
        entity_chunks.append((current_label, current_entity))
    
    # Nh√≥m theo lo·∫°i th·ª±c th·ªÉ
    for label, entity in entity_chunks:
        extracted_info.setdefault(label, []).append(entity)
    
    return extracted_info, entity_chunks

def format_output(text, entities, entity_chunks):
    output = f"### VƒÉn b·∫£n g·ªëc:\n{text}\n\n"
    output += "### K·∫øt qu·∫£ nh·∫≠n di·ªán th·ª±c th·ªÉ:\n"
    
    if entities:
        for entity_type, tokens in entities.items():
            unique_tokens = list(set(tokens))  # Lo·∫°i b·ªè tr√πng l·∫∑p
            description = ENTITY_DESCRIPTIONS.get(entity_type, "Th·ª±c th·ªÉ kh√°c")
            output += f"- **{description}**: {', '.join(unique_tokens)}\n"
    else:
        output += "*Kh√¥ng t√¨m th·∫•y th·ª±c th·ªÉ n√†o trong vƒÉn b·∫£n.*"
    
    output += "\n### Danh s√°ch c·ª•m th·ª±c th·ªÉ:\n"
    for label, entity in entity_chunks:
        output += f"- **{ENTITY_DESCRIPTIONS.get(label, 'Th·ª±c th·ªÉ kh√°c')}:** {entity}\n"
    
    return output

# Streamlit UI
st.title("üîé ·ª®ng d·ª•ng Nh·∫≠n di·ªán Th·ª±c th·ªÉ (NER)")
st.write("·ª®ng d·ª•ng gi√∫p tr√≠ch xu·∫•t th√¥ng tin quan tr·ªçng t·ª´ vƒÉn b·∫£n b·∫±ng m√¥ h√¨nh AI.")

user_input = st.text_area("Nh·∫≠p vƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch:", "")

if st.button("Nh·∫≠n di·ªán th·ª±c th·ªÉ"):
    if user_input:
        st.session_state.total_inputs.append(user_input)
        
        # X·ª≠ l√Ω m√¥ h√¨nh spaCy
        extracted_entities_spacy, entity_chunks = extract_entities(user_input)
        formatted_text_spacy = format_output(user_input, extracted_entities_spacy, entity_chunks)

        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        st.subheader("üìå K·∫øt qu·∫£ t·ª´ m√¥ h√¨nh AI:")
        st.markdown(formatted_text_spacy)
        
        # L∆∞u k·∫øt qu·∫£ ƒë·ªÉ t·∫£i xu·ªëng
        all_inputs_with_entities = []
        for text in st.session_state.total_inputs:
            extracted_entities_spacy, entity_chunks = extract_entities(text)
            formatted_text_spacy = format_output(text, extracted_entities_spacy, entity_chunks)
            all_inputs_with_entities.append(formatted_text_spacy)
        
        all_inputs_with_entities_text = "\n\n".join(all_inputs_with_entities)
        
        st.download_button(
            label="üì• T·∫£i xu·ªëng k·∫øt qu·∫£ nh·∫≠n di·ªán",
            data=all_inputs_with_entities_text,
            file_name="ket_qua_ner.txt",
            mime="text/plain"
        )
    else:
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p vƒÉn b·∫£n tr∆∞·ªõc khi ph√¢n t√≠ch.")